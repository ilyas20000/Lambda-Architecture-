[2023-12-25T13:32:40.709+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:32:40.718+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:32:40.719+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T13:32:40.740+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): batch_0> on 2023-12-24 00:00:00+00:00
[2023-12-25T13:32:40.746+0000] {standard_task_runner.py:60} INFO - Started process 309 to run task
[2023-12-25T13:32:40.751+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'batch_layer', 'batch_0', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/BatchLayerDag.py', '--cfg-path', '/tmp/tmpnl4xu9pe']
[2023-12-25T13:32:40.754+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask batch_0
[2023-12-25T13:32:40.799+0000] {task_command.py:423} INFO - Running <TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [running]> on host f631e8536ec1
[2023-12-25T13:32:40.868+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='batch_layer' AIRFLOW_CTX_TASK_ID='batch_0' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T13:32:40.964+0000] {hive.py:475} INFO - USE `finnhub_db`
[2023-12-25T13:32:41.016+0000] {hive.py:475} INFO - 
                SELECT *
                FROM finnhub_table
            
[2023-12-25T13:32:41.481+0000] {logging_mixin.py:188} INFO -          date  hour        s      sum_v
0  2023-12-25    13  BINANCE  161.57425
[2023-12-25T13:32:41.484+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/parquet_output.parquet' already exists.
[2023-12-25T13:32:41.570+0000] {logging_mixin.py:188} INFO -          date  hour        s      sum_v
0  2023-12-25    13  BINANCE  161.57425
[2023-12-25T13:32:41.571+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T13:32:41.579+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=batch_layer, task_id=batch_0, execution_date=20231224T000000, start_date=20231225T133240, end_date=20231225T133241
[2023-12-25T13:32:41.607+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T13:32:41.622+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T14:31:03.821+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T14:31:03.827+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T14:31:03.827+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T14:31:03.839+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): batch_0> on 2023-12-24 00:00:00+00:00
[2023-12-25T14:31:03.844+0000] {standard_task_runner.py:60} INFO - Started process 310 to run task
[2023-12-25T14:31:03.846+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'batch_layer', 'batch_0', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/BatchLayerDag.py', '--cfg-path', '/tmp/tmp4r5hq51t']
[2023-12-25T14:31:03.848+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask batch_0
[2023-12-25T14:31:03.887+0000] {task_command.py:423} INFO - Running <TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [running]> on host 9bdca13f3810
[2023-12-25T14:31:03.973+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='batch_layer' AIRFLOW_CTX_TASK_ID='batch_0' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T14:31:04.042+0000] {hive.py:475} INFO - USE `finnhub_db`
[2023-12-25T14:31:04.082+0000] {hive.py:475} INFO - 
                SELECT *
                FROM finnhub_table
            
[2023-12-25T14:31:04.976+0000] {logging_mixin.py:188} INFO -          date  hour        s      sum_v
0  2023-12-25    13  BINANCE  472.98830
1  2023-12-25    14  BINANCE  830.14797
[2023-12-25T14:31:04.977+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/parquet_output.parquet' already exists.
[2023-12-25T14:31:05.070+0000] {logging_mixin.py:188} INFO -          date  hour        s      sum_v
0  2023-12-25    13  BINANCE  472.98830
1  2023-12-25    14  BINANCE  830.14797
[2023-12-25T14:31:05.071+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T14:31:05.076+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=batch_layer, task_id=batch_0, execution_date=20231224T000000, start_date=20231225T143103, end_date=20231225T143105
[2023-12-25T14:31:05.103+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T14:31:05.114+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T19:48:34.044+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T19:48:34.050+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T19:48:34.051+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T19:48:34.066+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): batch_0> on 2023-12-24 00:00:00+00:00
[2023-12-25T19:48:34.073+0000] {standard_task_runner.py:60} INFO - Started process 310 to run task
[2023-12-25T19:48:34.081+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'batch_layer', 'batch_0', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/BatchLayerDag.py', '--cfg-path', '/tmp/tmp28pjj15o']
[2023-12-25T19:48:34.085+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask batch_0
[2023-12-25T19:48:34.143+0000] {task_command.py:423} INFO - Running <TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [running]> on host e9f65bff2772
[2023-12-25T19:48:34.219+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='batch_layer' AIRFLOW_CTX_TASK_ID='batch_0' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T19:48:34.293+0000] {hive.py:475} INFO - USE `finnhub_db`
[2023-12-25T19:48:34.343+0000] {hive.py:475} INFO - 
                SELECT *
                FROM finnhub_table
            
[2023-12-25T19:48:36.401+0000] {logging_mixin.py:188} INFO -          date  hour        s       sum_v
0  2023-12-25    13  BINANCE  1656.36169
1  2023-12-25    14  BINANCE  5144.59064
2  2023-12-25    18  BINANCE  2516.97871
[2023-12-25T19:48:36.403+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/parquet_output.parquet' already exists.
[2023-12-25T19:48:36.474+0000] {logging_mixin.py:188} INFO -          date  hour        s       sum_v
0  2023-12-25    13  BINANCE  1656.36169
1  2023-12-25    14  BINANCE  5144.59064
2  2023-12-25    18  BINANCE  2516.97871
[2023-12-25T19:48:36.480+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T19:48:36.486+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=batch_layer, task_id=batch_0, execution_date=20231224T000000, start_date=20231225T194834, end_date=20231225T194836
[2023-12-25T19:48:36.540+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T19:48:36.551+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T21:01:28.470+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T21:01:28.476+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T21:01:28.476+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T21:01:28.487+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): batch_0> on 2023-12-24 00:00:00+00:00
[2023-12-25T21:01:28.490+0000] {standard_task_runner.py:60} INFO - Started process 299 to run task
[2023-12-25T21:01:28.492+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'batch_layer', 'batch_0', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/BatchLayerDag.py', '--cfg-path', '/tmp/tmpw3jn6km_']
[2023-12-25T21:01:28.494+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask batch_0
[2023-12-25T21:01:28.522+0000] {task_command.py:423} INFO - Running <TaskInstance: batch_layer.batch_0 scheduled__2023-12-24T00:00:00+00:00 [running]> on host 5e983ae2bbe8
[2023-12-25T21:01:28.563+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='batch_layer' AIRFLOW_CTX_TASK_ID='batch_0' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T21:01:28.616+0000] {hive.py:475} INFO - USE `finnhub_db`
[2023-12-25T21:01:28.666+0000] {hive.py:475} INFO - 
                SELECT *
                FROM finnhub_table
            
[2023-12-25T21:01:31.451+0000] {logging_mixin.py:188} INFO -          date  hour        s       sum_v
0  2023-12-25    13  BINANCE  1718.64450
1  2023-12-25    14  BINANCE  5371.66657
2  2023-12-25    18  BINANCE  2765.09680
3  2023-12-25    20  BINANCE    10.94890
[2023-12-25T21:01:31.453+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/parquet_output.parquet' already exists.
[2023-12-25T21:01:31.499+0000] {logging_mixin.py:188} INFO -          date  hour        s       sum_v
0  2023-12-25    13  BINANCE  1718.64450
1  2023-12-25    14  BINANCE  5371.66657
2  2023-12-25    18  BINANCE  2765.09680
3  2023-12-25    20  BINANCE    10.94890
[2023-12-25T21:01:31.505+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T21:01:31.509+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=batch_layer, task_id=batch_0, execution_date=20231224T000000, start_date=20231225T210128, end_date=20231225T210131
[2023-12-25T21:01:31.556+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T21:01:31.565+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check

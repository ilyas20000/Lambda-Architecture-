[2023-12-24T15:36:59.841+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T15:36:59.846+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T15:36:59.846+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T15:36:59.970+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T15:36:59.976+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T15:36:59.978+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpe4lz79h1']
[2023-12-24T15:36:59.980+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T15:37:00.098+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host b2aeaa9190f5
[2023-12-24T15:37:00.325+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T15:37:00.342+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T15:37:00.782+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T15:37:00.783+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T15:37:00.787+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T153659, end_date=20231224T153700
[2023-12-24T15:37:00.954+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T15:37:00.963+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T15:41:54.522+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T15:41:54.532+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T15:41:54.533+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T15:41:54.554+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T15:41:54.564+0000] {standard_task_runner.py:60} INFO - Started process 162 to run task
[2023-12-24T15:41:54.573+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpj5cwxj3r']
[2023-12-24T15:41:54.580+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T15:41:54.662+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host 83b53490fe78
[2023-12-24T15:41:54.762+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T15:41:54.767+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T15:41:54.881+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T15:41:54.882+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T15:41:54.888+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T154154, end_date=20231224T154154
[2023-12-24T15:41:54.947+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T15:41:54.961+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T15:51:26.293+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T15:51:26.298+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T15:51:26.298+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T15:51:26.312+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T15:51:26.317+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T15:51:26.320+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpkip13b27']
[2023-12-24T15:51:26.322+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T15:51:26.355+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host be1f0ffa1f05
[2023-12-24T15:51:26.415+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T15:51:26.418+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T15:51:26.458+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T15:51:26.459+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T15:51:26.464+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T155126, end_date=20231224T155126
[2023-12-24T15:51:26.493+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T15:51:26.515+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T17:03:11.109+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T17:03:11.115+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T17:03:11.116+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T17:03:11.129+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T17:03:11.136+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T17:03:11.143+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmp65ijn5jj']
[2023-12-24T17:03:11.150+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T17:03:11.209+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host 1e3b18e1227a
[2023-12-24T17:03:11.292+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T17:03:11.297+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T17:03:11.414+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T17:03:11.414+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T17:03:11.419+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T170311, end_date=20231224T170311
[2023-12-24T17:03:11.475+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T17:03:11.488+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T17:48:17.765+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T17:48:17.770+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T17:48:17.771+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T17:48:17.783+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T17:48:17.788+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T17:48:17.791+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpp3tmwjrk']
[2023-12-24T17:48:17.793+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T17:48:17.827+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host 16ee60c2f1f1
[2023-12-24T17:48:17.876+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T17:48:17.879+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T17:48:17.956+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T17:48:17.957+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T17:48:17.962+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T174817, end_date=20231224T174817
[2023-12-24T17:48:18.004+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T17:48:18.013+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T18:11:22.534+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T18:11:22.539+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T18:11:22.540+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T18:11:22.551+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T18:11:22.556+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T18:11:22.558+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmppb_vx9w2']
[2023-12-24T18:11:22.561+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T18:11:22.592+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host c0475b589502
[2023-12-24T18:11:22.634+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T18:11:22.637+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T18:11:22.782+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T18:11:22.782+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T18:11:22.786+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T181122, end_date=20231224T181122
[2023-12-24T18:11:22.812+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T18:11:22.820+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T19:01:11.683+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T19:01:11.688+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T19:01:11.688+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T19:01:11.705+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T19:01:11.709+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T19:01:11.712+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmppui4zt87']
[2023-12-24T19:01:11.713+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T19:01:11.747+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host fffebfb72bbc
[2023-12-24T19:01:11.792+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T19:01:11.794+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T19:01:11.873+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T19:01:11.874+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T19:01:11.878+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T190111, end_date=20231224T190111
[2023-12-24T19:01:11.924+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T19:01:11.933+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-24T19:06:11.311+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T19:06:11.316+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [queued]>
[2023-12-24T19:06:11.317+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-24T19:06:11.331+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-23 00:00:00+00:00
[2023-12-24T19:06:11.337+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-24T19:06:11.340+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-23T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpc8vzl2se']
[2023-12-24T19:06:11.343+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-24T19:06:11.381+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-23T00:00:00+00:00 [running]> on host 465cb068660d
[2023-12-24T19:06:11.433+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-23T00:00:00+00:00'
[2023-12-24T19:06:11.436+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-24T19:06:11.511+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-24T19:06:11.511+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-24T19:06:11.515+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231223T000000, start_date=20231224T190611, end_date=20231224T190611
[2023-12-24T19:06:11.553+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-24T19:06:11.561+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check

[2023-12-25T13:10:45.151+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:10:45.159+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:10:45.160+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T13:10:45.178+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T13:10:45.184+0000] {standard_task_runner.py:60} INFO - Started process 165 to run task
[2023-12-25T13:10:45.187+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpjmv8hczr']
[2023-12-25T13:10:45.190+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T13:10:45.228+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host f631e8536ec1
[2023-12-25T13:10:45.285+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T13:10:45.290+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T13:10:45.399+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T13:10:45.400+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T13:10:45.406+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T131045, end_date=20231225T131045
[2023-12-25T13:10:45.442+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T13:10:45.454+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T13:38:21.731+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:38:21.738+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:38:21.739+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T13:38:23.988+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T13:38:23.994+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-25T13:38:23.997+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpgcf_fyw_']
[2023-12-25T13:38:24.000+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T13:38:24.078+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host f6690199a9a1
[2023-12-25T13:38:24.328+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T13:38:24.333+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T13:38:24.413+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T13:38:24.414+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T13:38:24.420+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T133821, end_date=20231225T133824
[2023-12-25T13:38:24.453+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T13:38:24.464+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T13:47:44.977+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:47:44.981+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T13:47:44.982+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T13:47:44.992+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T13:47:44.996+0000] {standard_task_runner.py:60} INFO - Started process 162 to run task
[2023-12-25T13:47:44.998+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmp9td4hljb']
[2023-12-25T13:47:44.999+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T13:47:45.031+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host 43991cd2d77a
[2023-12-25T13:47:45.071+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T13:47:45.073+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T13:47:45.116+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T13:47:45.117+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T13:47:45.121+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T134744, end_date=20231225T134745
[2023-12-25T13:47:45.170+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T13:47:45.179+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T14:11:28.333+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T14:11:28.338+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T14:11:28.339+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T14:11:28.350+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T14:11:28.353+0000] {standard_task_runner.py:60} INFO - Started process 165 to run task
[2023-12-25T14:11:28.355+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpquccpixc']
[2023-12-25T14:11:28.356+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T14:11:28.381+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host 9bdca13f3810
[2023-12-25T14:11:28.422+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T14:11:28.425+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T14:11:28.501+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T14:11:28.502+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T14:11:28.505+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T141128, end_date=20231225T141128
[2023-12-25T14:11:28.528+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T14:11:28.535+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T18:26:19.480+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T18:26:19.485+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T18:26:19.485+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T18:26:19.496+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T18:26:19.500+0000] {standard_task_runner.py:60} INFO - Started process 165 to run task
[2023-12-25T18:26:19.502+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpx91gi6ad']
[2023-12-25T18:26:19.504+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T18:26:19.533+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host e9f65bff2772
[2023-12-25T18:26:19.575+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T18:26:19.578+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T18:26:19.646+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T18:26:19.647+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T18:26:19.650+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T182619, end_date=20231225T182619
[2023-12-25T18:26:19.675+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T18:26:19.683+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T20:02:24.786+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:02:24.792+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:02:24.793+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T20:02:24.805+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T20:02:24.810+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-25T20:02:24.812+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmp49477z8c']
[2023-12-25T20:02:24.814+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T20:02:24.854+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host 9a3f62d5a7ea
[2023-12-25T20:02:24.902+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T20:02:24.905+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T20:02:24.966+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T20:02:24.967+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T20:02:24.975+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T200224, end_date=20231225T200224
[2023-12-25T20:02:25.025+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T20:02:25.034+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T20:21:04.364+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:21:04.370+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:21:04.370+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T20:21:04.384+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T20:21:04.389+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-25T20:21:04.392+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpjoupz6c9']
[2023-12-25T20:21:04.395+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T20:21:04.428+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host ccce5d2e349d
[2023-12-25T20:21:04.508+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T20:21:04.511+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T20:21:04.591+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T20:21:04.592+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T20:21:04.596+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T202104, end_date=20231225T202104
[2023-12-25T20:21:04.645+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T20:21:04.654+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T20:40:06.683+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:40:06.693+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:40:06.694+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T20:40:06.720+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T20:40:06.726+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-25T20:40:06.731+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpdkhnj1wu']
[2023-12-25T20:40:06.734+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T20:40:06.786+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host 95df9ca91b9b
[2023-12-25T20:40:06.875+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T20:40:06.880+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T20:40:07.007+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T20:40:07.008+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T20:40:07.016+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T204006, end_date=20231225T204007
[2023-12-25T20:40:07.065+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T20:40:07.085+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T20:48:53.969+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:48:53.976+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:48:53.977+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T20:48:53.992+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T20:48:53.998+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-25T20:48:54.002+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpc52cyucg']
[2023-12-25T20:48:54.006+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T20:48:54.049+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host 358dd0754c02
[2023-12-25T20:48:54.152+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T20:48:54.155+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T20:48:54.261+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T20:48:54.262+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T20:48:54.268+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T204853, end_date=20231225T204854
[2023-12-25T20:48:54.296+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T20:48:54.309+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-12-25T20:50:31.654+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:50:31.663+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [queued]>
[2023-12-25T20:50:31.663+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2023-12-25T20:50:31.684+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): parquet> on 2023-12-24 00:00:00+00:00
[2023-12-25T20:50:31.692+0000] {standard_task_runner.py:60} INFO - Started process 161 to run task
[2023-12-25T20:50:31.704+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'parquet', 'parquet', 'scheduled__2023-12-24T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/parquet.py', '--cfg-path', '/tmp/tmpmktimniv']
[2023-12-25T20:50:31.715+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask parquet
[2023-12-25T20:50:31.789+0000] {task_command.py:423} INFO - Running <TaskInstance: parquet.parquet scheduled__2023-12-24T00:00:00+00:00 [running]> on host 5e983ae2bbe8
[2023-12-25T20:50:31.912+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='parquet' AIRFLOW_CTX_TASK_ID='parquet' AIRFLOW_CTX_EXECUTION_DATE='2023-12-24T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-24T00:00:00+00:00'
[2023-12-25T20:50:31.916+0000] {logging_mixin.py:188} INFO - File '/tmp/batchViews/df.parquet' already exists.
[2023-12-25T20:50:32.019+0000] {logging_mixin.py:188} INFO -    column1 column2
0        1  value1
1        2  value2
[2023-12-25T20:50:32.021+0000] {python.py:201} INFO - Done. Returned value was: None
[2023-12-25T20:50:32.027+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=parquet, task_id=parquet, execution_date=20231224T000000, start_date=20231225T205031, end_date=20231225T205032
[2023-12-25T20:50:32.073+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2023-12-25T20:50:32.087+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
